# evaluation_multimodal.py
import os
import sys
import asyncio
from dotenv import load_dotenv
from datasets import Dataset
from ragas.evaluation import evaluate
from ragas.metrics import (
    context_precision,
    context_recall,
    answer_relevancy,
    faithfulness,
    answer_similarity
)

# âœ… ê²½ë¡œ ì„¤ì • ë° í•¨ìˆ˜ import
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "src", "backend", "utils")))
from rag_module import get_recycling_answer, vector_db
from yolo_infer import predict_topk_from_bytes

load_dotenv()

retriever = vector_db.as_retriever(search_type="mmr", search_kwargs={"k": 3})

# âœ… í‰ê°€ìš© ì´ë¯¸ì§€ & ì§ˆë¬¸ ë°ì´í„°
samples = [
    {
        "image_path": "./test_images/glass_bottle.png",
        "question": "ì´ ë³‘ì€ ì–´ë–»ê²Œ ë²„ë¦¬ë‚˜ìš”?",
        "ground_truth": "ê¹¨ì§„ ìœ ë¦¬ëŠ” ì‹ ë¬¸ì§€ë¡œ ì‹¸ì„œ ì¢…ëŸ‰ì œ ë´‰íˆ¬ì— ë²„ë¦°ë‹¤."
    },
    {
        "image_path": "./test_images/milk_pack.png",
        "question": "ìš°ìœ íŒ©ì€ ì¢…ì´ë¥˜ë¡œ ë²„ë¦¬ë©´ ë˜ë‚˜ìš”?",
        "ground_truth": "ì¢…ì´íŒ©ê³¼ ì¢…ì´ë¥˜ëŠ” ì„œë¡œ ë‹¤ë¥¸ ì¬í™œìš© ê³µì •ì„ ê±°ì¹˜ê¸° ë•Œë¬¸ì— êµ¬ë¶„í•˜ì—¬ ë°°ì¶œí•œë‹¤."
    },
    {
        "image_path": "./test_images/aluminum_can.png",
        "question": "ì´ ìº” ê·¸ëƒ¥ ë²„ë ¤ë„ ë˜ë‚˜ìš”?",
        "ground_truth": "ê¸ˆì†ìº”ì€ ë‚´ìš©ë¬¼ì„ ë¹„ìš°ê³  ì´ë¬¼ì§ˆì„ ì œê±°í•œ ë’¤ ë‹´ë°°ê½ì´ˆëŠ” ë„£ì§€ ì•Šê³  ë°°ì¶œí•œë‹¤."
    }
]

metrics = [
    context_precision,
    context_recall,
    answer_relevancy,
    faithfulness,
    answer_similarity
]

results = {"question": [], "answer": [], "contexts": [], "ground_truth": [], "case": []}

def collect_contexts(query):
    docs = retriever.invoke(query)
    return [doc.page_content for doc in docs]

# âœ… ë¹„ë™ê¸° í‰ê°€ ë£¨í”„
async def main():
    for case in ["question_only", "image_only", "multimodal"]:
        for sample in samples:
            image_item = None
            question = None

            # ğŸ” YOLO ì˜ˆì¸¡ (await í•„ìˆ˜!)
            with open(sample["image_path"], "rb") as f:
                file_bytes = f.read()
                preds = predict_topk_from_bytes(file_bytes, top_k=1)
                image_item = preds[0]["item"]

            if case == "question_only":
                question = sample["question"]
                answer = get_recycling_answer(None, question)
                context = collect_contexts(question)

            elif case == "image_only":
                question = None
                answer = get_recycling_answer(image_item, None)
                context = collect_contexts(image_item)

            elif case == "multimodal":
                question = sample["question"]
                answer = get_recycling_answer(image_item, question)
                context = collect_contexts(f"{image_item} {question}")

            results["question"].append(question if question else f"(ì´ë¯¸ì§€: {image_item})")
            results["answer"].append(answer)
            results["contexts"].append(context)
            results["ground_truth"].append(sample["ground_truth"])
            results["case"].append(case)

    dataset = Dataset.from_dict(results)
    result = evaluate(dataset, metrics)

    print("\nâœ… RAGAS ë©€í‹°ëª¨ë‹¬ í‰ê°€ ê²°ê³¼")
    print(result)

# âœ… ì‹¤í–‰
if __name__ == "__main__":
    asyncio.run(main())
